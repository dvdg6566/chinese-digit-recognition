{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.5,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=(26,26,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=[\"categorical_accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3030 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.5,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    \n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"./indiv/train\",\n",
    "    target_size=(26,26),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = \"categorical\",\n",
    "    color_mode = \"grayscale\"\n",
    "    \n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    './indiv/test',\n",
    "    target_size =(26,26),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = \"categorical\",\n",
    "    color_mode =\"grayscale\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 2.3039 - categorical_accuracy: 0.0994 - val_loss: 2.3032 - val_categorical_accuracy: 0.0938\n",
      "Epoch 2/200\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 2.3031 - categorical_accuracy: 0.0897 - val_loss: 2.3024 - val_categorical_accuracy: 0.1324\n",
      "Epoch 3/200\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 2.3039 - categorical_accuracy: 0.0964 - val_loss: 2.3022 - val_categorical_accuracy: 0.0882\n",
      "Epoch 4/200\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 2.3029 - categorical_accuracy: 0.0941 - val_loss: 2.3023 - val_categorical_accuracy: 0.1176\n",
      "Epoch 5/200\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 2.3028 - categorical_accuracy: 0.1017 - val_loss: 2.3023 - val_categorical_accuracy: 0.1042\n",
      "Epoch 6/200\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 2.3028 - categorical_accuracy: 0.0954 - val_loss: 2.3011 - val_categorical_accuracy: 0.1176\n",
      "Epoch 7/200\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 2.3023 - categorical_accuracy: 0.0982 - val_loss: 2.2973 - val_categorical_accuracy: 0.1176\n",
      "Epoch 8/200\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 2.2987 - categorical_accuracy: 0.1198 - val_loss: 2.2996 - val_categorical_accuracy: 0.1176\n",
      "Epoch 9/200\n",
      "94/94 [==============================] - 5s 55ms/step - loss: 2.2908 - categorical_accuracy: 0.1318 - val_loss: 2.2693 - val_categorical_accuracy: 0.1042\n",
      "Epoch 10/200\n",
      "94/94 [==============================] - 5s 57ms/step - loss: 2.2602 - categorical_accuracy: 0.1517 - val_loss: 2.2259 - val_categorical_accuracy: 0.0735\n",
      "Epoch 11/200\n",
      "19/94 [=====>........................] - ETA: 4s - loss: 2.1932 - categorical_accuracy: 0.1853"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-69ab809eb41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/.virtualenvs/imagepy/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/imagepy/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/imagepy/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/imagepy/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=3030//batch_size,\n",
    "    epochs = 200,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = 100//batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save(\"accuracy-87.5.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 10 classes.\n",
      "0.8375\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    './indiv/val',\n",
    "    target_size =(26,26),\n",
    "    batch_size = 1,\n",
    "    class_mode = \"categorical\",\n",
    "    color_mode =\"grayscale\"\n",
    ")\n",
    "\n",
    "print(model.evaluate_generator(validation_generator,steps=80)[1])\n",
    "\n",
    "# print(validation_generator.filenames)\n",
    "\n",
    "# predictions.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4 = Sequential()\n",
    "cnn4.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(26,26,1)))\n",
    "cnn4.add(BatchNormalization())\n",
    "\n",
    "cnn4.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn4.add(Dropout(0.25))\n",
    "\n",
    "cnn4.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(Dropout(0.25))\n",
    "\n",
    "cnn4.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn4.add(Dropout(0.25))\n",
    "\n",
    "cnn4.add(Flatten())\n",
    "\n",
    "cnn4.add(Dense(512, activation='relu'))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(Dropout(0.5))\n",
    "\n",
    "cnn4.add(Dense(128, activation='relu'))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(Dropout(0.5))\n",
    "\n",
    "cnn4.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn4.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# cnn4.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=3030//batch_size,\n",
    "#     epochs = 13,\n",
    "#     validation_data = test_generator,\n",
    "#     validation_steps = 100//batch_size\n",
    "# )\n",
    "\n",
    "\n",
    "# validation_generator = test_datagen.flow_from_directory(\n",
    "#     './indiv/val',\n",
    "#     target_size =(26,26),\n",
    "#     batch_size = 1,\n",
    "#     class_mode = \"categorical\",\n",
    "#     color_mode =\"grayscale\"\n",
    "# )\n",
    "\n",
    "# print(cnn4.evaluate_generator(validation_generator,steps=80)[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4670 - acc: 0.8448 - val_loss: 1.0609 - val_acc: 0.7059\n",
      "150 0.7375\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.5226 - acc: 0.8227 - val_loss: 6.5646 - val_acc: 0.2206\n",
      "151 0.3\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.5289 - acc: 0.8184 - val_loss: 1.1480 - val_acc: 0.5882\n",
      "152 0.7\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 12s 128ms/step - loss: 0.4951 - acc: 0.8323 - val_loss: 2.5911 - val_acc: 0.5441\n",
      "153 0.55\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 0.5336 - acc: 0.8255 - val_loss: 1.2231 - val_acc: 0.5735\n",
      "154 0.6375\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 114ms/step - loss: 0.4976 - acc: 0.8322 - val_loss: 0.2851 - val_acc: 0.8958\n",
      "155 0.875\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.5322 - acc: 0.8266 - val_loss: 4.5423 - val_acc: 0.3235\n",
      "156 0.4\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.5052 - acc: 0.8355 - val_loss: 0.3002 - val_acc: 0.8824\n",
      "157 0.8875\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 12s 123ms/step - loss: 0.5252 - acc: 0.8252 - val_loss: 0.5207 - val_acc: 0.8529\n",
      "158 0.8875\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 119ms/step - loss: 0.4823 - acc: 0.8391 - val_loss: 0.6685 - val_acc: 0.7941\n",
      "159 0.7875\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4787 - acc: 0.8425 - val_loss: 0.6545 - val_acc: 0.7604\n",
      "160 0.7625\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.5117 - acc: 0.8235 - val_loss: 1.2704 - val_acc: 0.6471\n",
      "161 0.75\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4872 - acc: 0.8420 - val_loss: 3.4789 - val_acc: 0.4412\n",
      "162 0.4\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 118ms/step - loss: 0.5004 - acc: 0.8327 - val_loss: 5.3843 - val_acc: 0.2059\n",
      "163 0.2125\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4884 - acc: 0.8388 - val_loss: 0.6500 - val_acc: 0.8088\n",
      "164 0.8125\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4957 - acc: 0.8407 - val_loss: 0.3189 - val_acc: 0.8971\n",
      "165 0.9125\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 0.4988 - acc: 0.8355 - val_loss: 0.2433 - val_acc: 0.8971\n",
      "166 0.8875\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 118ms/step - loss: 0.4731 - acc: 0.8490 - val_loss: 2.1422 - val_acc: 0.4706\n",
      "167 0.425\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.5241 - acc: 0.8233 - val_loss: 2.0058 - val_acc: 0.4559\n",
      "168 0.475\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 0.4727 - acc: 0.8492 - val_loss: 0.7442 - val_acc: 0.7941\n",
      "169 0.7875\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 0.4875 - acc: 0.8393 - val_loss: 0.3827 - val_acc: 0.8971\n",
      "170 0.8125\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 0.5037 - acc: 0.8341 - val_loss: 6.0324 - val_acc: 0.2059\n",
      "171 0.2625\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4726 - acc: 0.8489 - val_loss: 0.4464 - val_acc: 0.8676\n",
      "172 0.8375\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.5216 - acc: 0.8225 - val_loss: 2.2001 - val_acc: 0.5588\n",
      "173 0.5375\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 0.4688 - acc: 0.8463 - val_loss: 0.3933 - val_acc: 0.8824\n",
      "174 0.925\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.5021 - acc: 0.8259 - val_loss: 0.3779 - val_acc: 0.8382\n",
      "175 0.95\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.5120 - acc: 0.8312 - val_loss: 0.2146 - val_acc: 0.9412\n",
      "176 0.8875\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4872 - acc: 0.8332 - val_loss: 0.3857 - val_acc: 0.8529\n",
      "177 0.9125\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.5058 - acc: 0.8323 - val_loss: 0.3119 - val_acc: 0.8971\n",
      "178 0.8625\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.4618 - acc: 0.8473 - val_loss: 3.3728 - val_acc: 0.5000\n",
      "179 0.4875\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4809 - acc: 0.8415 - val_loss: 4.8243 - val_acc: 0.3676\n",
      "180 0.2875\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4892 - acc: 0.8375 - val_loss: 0.8018 - val_acc: 0.7206\n",
      "181 0.7875\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.4626 - acc: 0.8468 - val_loss: 2.4985 - val_acc: 0.5147\n",
      "182 0.575\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4687 - acc: 0.8448 - val_loss: 0.4391 - val_acc: 0.8676\n",
      "183 0.825\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.5007 - acc: 0.8390 - val_loss: 0.4628 - val_acc: 0.8235\n",
      "184 0.825\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4917 - acc: 0.8388 - val_loss: 0.9433 - val_acc: 0.7083\n",
      "185 0.7\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 0.4626 - acc: 0.8415 - val_loss: 0.4522 - val_acc: 0.8382\n",
      "186 0.825\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.4965 - acc: 0.8352 - val_loss: 0.3206 - val_acc: 0.8824\n",
      "187 0.875\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4840 - acc: 0.8392 - val_loss: 1.3559 - val_acc: 0.5441\n",
      "188 0.5625\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4730 - acc: 0.8406 - val_loss: 0.3215 - val_acc: 0.9062\n",
      "189 0.95\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.4857 - acc: 0.8423 - val_loss: 0.2924 - val_acc: 0.8971\n",
      "190 0.9625\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 114ms/step - loss: 0.5219 - acc: 0.8259 - val_loss: 0.8998 - val_acc: 0.7353\n",
      "191 0.7\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 0.4676 - acc: 0.8458 - val_loss: 2.1495 - val_acc: 0.4853\n",
      "192 0.525\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.4461 - acc: 0.8552 - val_loss: 1.2706 - val_acc: 0.7206\n",
      "193 0.775\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.4872 - acc: 0.8372 - val_loss: 0.3136 - val_acc: 0.8529\n",
      "194 0.9125\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.4611 - acc: 0.8443 - val_loss: 0.3634 - val_acc: 0.8958\n",
      "195 0.8625\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.4514 - acc: 0.8472 - val_loss: 2.5150 - val_acc: 0.4706\n",
      "196 0.4625\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.4852 - acc: 0.8385 - val_loss: 0.1980 - val_acc: 0.9559\n",
      "197 0.9125\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.4868 - acc: 0.8368 - val_loss: 0.5457 - val_acc: 0.8088\n",
      "198 0.85\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 11s 115ms/step - loss: 0.4941 - acc: 0.8393 - val_loss: 0.4235 - val_acc: 0.8676\n",
      "199 0.8375\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    './indiv/val',\n",
    "    target_size =(26,26),\n",
    "    batch_size = 1,\n",
    "    class_mode = \"categorical\",\n",
    "    color_mode =\"grayscale\"\n",
    ")\n",
    "\n",
    "for i in range(150,200):\n",
    "    cnn4.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=3030//batch_size,\n",
    "        epochs = 1,\n",
    "        validation_data = test_generator,\n",
    "        validation_steps = 100//batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "    x = cnn4.evaluate_generator(validation_generator,steps=80)[1]\n",
    "    print(i,x)\n",
    "    if (x > 0.98):break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4.save(\"ccn4-accuracy-97.5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"ccn4-accuracy-97.5.h5\")\n",
    "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def pred_img(img_path):\n",
    "    img = image.load_img(img_path, target_size=(26,26), grayscale=True)\n",
    "    arr = image.img_to_array(img)\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    arr /= 255.\n",
    "    def m(x):\n",
    "        if x == 0:return 1\n",
    "        if x == 1:return 10\n",
    "        return x\n",
    "    return m(model.predict_classes(test))\n",
    "\n",
    "\n",
    "pred_img(\"./ooo.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
